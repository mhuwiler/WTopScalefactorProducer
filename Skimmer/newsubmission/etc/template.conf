; Template of Grid Control (GC) configuration script used for production 

[global]
variable markers   = @
task        = UserTask      ; Job uses user written scripts
backend     = $backend$         ; Send to local batch system (slurm)
workdir = $workdir$			; The work directory where the logs and information about the jobs for GC are stored 

[condor]
jdldata =
	+use_x509userproxy=true

[local]
queue = $queue$					; The name of the queue to which submit the jobs
scratch path = $scratchpath$	; The path to the scratch directory on the worker node 

[backend]
proxy = VomsProxy

[jobs]
wall time   = $maxtime$:00:00 	; Max amount of time each job will take
in flight = 500 				; Maximum number of jobs submitted at the same time 
max retry = 10 			; Maximum number of resubmissions for failed jobs 

[UserTask]
executable  = executable.sh   	; Name of the script
dataset     = 					; List of GC dataset files 
$dataset$
dataset splitter = FileBoundarySplitter
dataset refresh  = 4:00
input files = env.sh 			 	; Additional files to be transferred (env.sh is generated in makeJobConfig.py)
files per job = $multiplicity$  	; Number of files to process per job

[Task]
Memory = 2000

[storage]
se output files = out.root qualitycheck.pkl timing.dat			; The name of the files to transfer back from the scratch area 
se output pattern = job_@MY_JOBID@_@X@
se path = $sepath$/${GC_TASK_ID}/${DATASETPATH}/
;nickname source = Example05_dataset.MyNick
;dataset check nickname collision = ignore
;dataset refresh = 1
;partition processor += MetaPartitionProcessor
;partition metadata = META_KEY1 META_KEY2 META_KEY3

